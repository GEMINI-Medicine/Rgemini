---
title: "Introduction to statistical analyses with GEMINI data"
output:
  html_vignette:
    number_sections: true
    toc: true
    toc_depth: 2
    dfprint: kable

vignette: >
  %\VignetteIndexEntry{Statistics - Introduction}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}

---

```{r include = FALSE}

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5,
  warning = FALSE,
  message = FALSE
)

library(data.table)
library(tidyverse)
library(dplyr)
library(Rgemini)
library(lubridate)
library(kableExtra)

#rmarkdown::render("~/GitHub/Rgemini/vignettes/stats_intro.Rmd", output_dir = "/mnt/nfs/projects/research_projects/Rgemini/stats_vignette/")

```


*  *  *  *


# Introduction & overview

This vignette illustrates an example analysis with (dummy) GEMINI data. The goal of this vignette is to provide an educational resource for analysts to make informed decisions at each analysis step. Throughout the vignette, we also provide links to existing resources with more detailed explanations.

If you would like to discuss any topics in more detail, please use the [Rgemini discussion forum](https://github.com/GEMINI-Medicine/Rgemini/discussions/categories/statistics)


*  *  *  *

# Research question & conceptual model 

In this tutorial, we will consider a hypothetical research study to investigate the question:

> **What is the effect of patients' age on clinical outcomes (in-hospital mortality, length of stay (LOS)), among patients with pneumonia discharged between 2018 - 2020?**. 


## Study design

As a general first step in conducting a research study, researchers would carefully consider the study design most suitable for answering the research question. Although analysts typically do not come up the study design themselves, knowing the fundamentals of study designs would help in effective understanding of research proposals and communicating with PIs and other researchers. 

<br></br>
<details>
<summary>**Expand section to learn about study designs and data considerations**</summary>

- The choice of study design is critical as it sets the framework for conducting the research, directs the analysis method, and influences robustness and validity of the study findings. For example, a cohort study provides stronger evidence for causal relationships than a case-control study. 

- Below is a brief sketch of the core designs in clinical research. Check out these resources for a refresher on core study designs: [1](https://www.ncbi.nlm.nih.gov/books/NBK470342/), [2](https://doi.org/10.1016/S0140-6736(02)07283-5). Of note, although there are general core study designs, designs and their categorizations are not rigid, and there are more complex designs and grey areas that may not clearly distinguish one design from another.

```{r, echo=FALSE, out.width = "40%", fig.align = "center", fig.cap="<span style='color:grey; font-size:11px'> Figure 1. Common Study Designs. ([Grimes DA and Schulz KF. The Lancet, 2002](https://doi.org/10.1016/S0140-6736(02)07283-5)) </span> " }
knitr::include_graphics("figures/stat_vignette_study_design.png", dpi = 200)
```


- Clearly, the choice of study design is dependent on the nature of the data being used. 

  + In experimental studies, data collection is driven by specific research questions (researchers have control over participant recruitment, intervention assignment and measurements collection). 
  + In contrast, GEMINI data are sourced from **routine data** collected on the basis of hospital admissions primarily for administrative and clinical purposes, not tailored to answering any specific research question. 
  
  > <span style='font-size:12px'> **Routine data**: A major source of GEMINI data is routinely collected electronic health records (EHR). Thus, our data shares similar characteristics and considerations as other EHR-derived databases when conducting research. This topic is beyond the scope of this tutorial. You are encouraged to check out these review articles [1](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6724703/), [2](https://pubmed.ncbi.nlm.nih.gov/38273982/), [3](https://dcricollab.dcri.duke.edu/sites/NIHKR/KR/Acquiring%20and%20Using%20Electronic%20Health%20Record%20Data.pdf) for a general overview of using EHR-derived data for research (e.g. common terminology, data attributes, study designs, advantages and limitations. Note that these articles were written in a US setting but the discussed concepts are generally applicable). </span>

  + The nature of routine data makes GEMINI data particularly suitable for conducting **observational studies**. Below are some example observational studies conducted using GEMINI data:
    + Retrospective cohort: <span style='font-size:11px'> [Bai AD et al. CHEST, 2024](https://doi.org/10.1016/j.chest.2023.08.008). [McIntyre MT et al. CMAJ, 2023](https://doi.org/10.1503/cmaj.221732). [Doshi S et al. JAMA Intern Med., 2023](https://doi.org/10.1001/jamainternmed.2023.2629).</span>
    + Cross-sectional: <span style='font-size:11px'>[Razak F et al. CMAJ Open, 2020](https://doi.org/10.9778/cmajo.20200098), [Verma AA et al. CMAJ Open, 2019](https://doi.org/10.9778/cmajo.20180181)</span>
    + Other designs are possible, see [GEMINI publications](https://geminimedicine.ca/publications/)

</details>
<br></br>

With knowledge about study designs and GEMINI data characteristics, letâ€™s determine which study design would be suitable for addressing our research question.

- The exposure of interest is patient's age at admission. The outcomes of interest are in-hospital mortality and LOS.

- Experimental studies are not possible for this question (impossible for researchers to manipulate the exposure variable, age). The question is **observational** by nature, which is well suited for using GEMINI data.

- The question is looking to estimate the association (magnitude and direction) between patient's age at admission and their clinical outcomes. An analytical study rather than a descriptive study is required. Since in-hospital mortality and LOS can only be known after hospital admission, the temporal relationship between exposure and outcome is implied. Therefore, our research question calls for a **cohort study design**, which means that researchers would assemble a cohort of patients based on characteristics at admission (e.g. pneumonia) and then follow them over time for the occurrence of outcomes.

- As the outcomes of interest have already occurred upon data extraction, the cohort is considered retrospective.

- Therefore, a **retrospective cohort study** would be suitable for addressing the research question.


*  *  *  *

# Conceptualizing the Research Question

## Directed Acyclic Graphs
A visual, conceptual model can help understand the research question and how its components are related to one another. A directed acyclic graph (DAG) is a graphical representation of the relationship between the outcome, exposure, and related variables: [Digitale JC et al. J Clin Epidemiol, 2022](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8821727/). It can be helpful in picking a statistical model by 'drawing' out the assumptions between variables. The following DAG shows a simple theoretical causal relationship between age, the exposure variable, and in-hospital mortality, one of the outcomes of interest. 

```{r, echo=FALSE, out.width = "60%", fig.align = "center", fig.cap="<span style='color:grey; font-size:11px'> DAG of age and in-hospital mortality</span> " }
knitr::include_graphics("figures/dag_img1.png", dpi = 200)
```

<br></br>
<details>
<summary>**Expand section to learn more about DAGs**</summary>
- In a DAG, causal relationships are always unidirectional (i.e. age can be a cause of in-hospital mortality, but not the reverse). Two causal relationships following each other form a path.
- There are common ways of describing the relationship between nodes (i.e. variables): 1) parent and children (direct relationship), 2) descendants and ancestors (any node along the path to or from another node)
- A directed path describes a causal relationship between two nodes
- An indirect path describes a confounding relationship between two nodes
- For more information, check out these resources: [DAGs: A simple introduction with simulations in R](https://arelbundock.com/posts/acmq_en_06_dag/), [Applications of DAGs in Causal Inference](https://www.r-bloggers.com/2018/08/applications-of-dags-in-causal-inference/)
</details>

## Third Variables
While it is possible to estimate the effect of age on mortality on its own, often called an unadjusted model, it is common practice to control for variables that could have a direct or indirect cause on the exposure and outcome. These variables are called confounders (also referred to as covariates) and controlling for these variables debiases the association between the variables of interest: [Wysocki A et al. Adv Meth Pract Pyschol Sci, 2022](https://journals.sagepub.com/doi/10.1177/25152459221095823#:~:text=After%20outlining%20a%20causal%20structure,of%20the%20predictor%20and%20outcome). 

  - Gender can affect the age that one acquires pneumonia, along with the severity of illness            experienced when pneumonia is acquired: [Corica B et at. Intern   Emerg Med, 2022](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9294783/).
  - Charlson comorbidities are comorbid conditions that can be used to predict the risk of death and     should be controlled for when considering the outcome of death: [Charlson ME et al. J Chronic Dis, 1987](https://www.sciencedirect.com/science/article/abs/pii/0021968187901718).
  - mLAPS (modified laboratory acute physiology score) is an indicator of illness severity based on physiological lab data at or before admission  that is used to adjust for risk: [Roberts S et al. Preprint, 2023](https://www.medrxiv.org/content/10.1101/2023.01.06.23284273v1). GEMINI's in-house package, [Rgemini](https://gemini-medicine.github.io/Rgemini/reference/mlaps.html), is a fast and convenient way of deriving this variable.

Including additional variables in a statistical model is referred to as an adjusted model and can help better understand the causal relationship between an exposure and its outcome. The DAG below takes these variables into account. 
```{r, echo=FALSE, out.width = "60%", fig.align = "center", fig.cap="<span style='color:grey; font-size:11px'> DAG of age and in-hospital mortality, including confounders </span> " }
knitr::include_graphics("figures/dag_img2.png", dpi = 200)
```

Confounders are not the only variables that can affect the relationship between age and in-hospital mortality or LOS. Mediators, or intermediate variables, lie in the causal pathway between the exposure variable and outcome. In this analysis, a mediator would be caused by age and is a cause of the outcome variables. This type of analysis, mediation analysis, is beyond the scope of this study, but it is important to understand the distinction between controlling for a confounder that could bias results, and including mediators that block the path to an outcome: [MacKinnon D. Res Soc Work Pract, 2011](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3366634/)


## Cohort definition

Based on the conceptual model discussed above, we will define our cohort as follows:

+ **Inclusion steps**
  - Incl. 1: All GIM encounters discharged between Apr 2018 - Apr 2020
  - Incl. 2: Hospitals with high data coverage for relevant variables (here: administrative & lab data for `mlaps`)
  - Incl. 3: Encounters with Pneumonia as most responsible diagnosis code (MRDx)

+ **Exclusion steps:**
  - Excl. 1: Encounters transferred from another acute-care institute 
  - Excl. 2: Encounters not admitted from ED
  
The reason for the two exclusion steps is to make sure that any covariates we include as baseline characteristics (e.g., `mlaps` at admission) accurately reflect patients' condition when they first entered the hospital (rather than having received prior treatment at another healthcare facility they were transferred from). 


<details>
<summary>***Expand this section for some additional tips***</summary>

The cohort inclusion/exclusion steps should be developed in close collaboration between the clinical researcher and data analyst. Typically, the steps will need to be refined during the project kick-off meeting to make sure the specific criteria, sequence, and rationale for the cohort definition makes sense. The cohort creation steps may also need to be refined once the analyst has completed the data checks (see next section), which might reveal unforeseen challenges/data issues.

</details>



*  *  *  *

# Data checks & cohort generation

Now that we have clarified the conceptual framework and cohort definition, let's take a look at the data.

Here, we assume our cohort consists of all GIM encounters discharged between Apr 2018 - Apr 2020 (see incl. 1 above) from 20 hospitals. GIM encounters are defined as all encounters that were either admitted to/or discharged from GIM (see `gim_flag_derived` in the `derived_variables` table [**NOTE: This will be added to the next DB version**]).

We'll load this dummy data from a saved file and turn it into a `data.table` object:

```{r}
# read sample data
data <- readRDS("/mnt/nfs/projects/research_projects/Rgemini/stats_vignette/dummy_data_stats.rds") %>% 
  data.table()
```

To briefly inspect the variables in our data table, we can use `head():`

```{r}
head(data)
```

The [GEMINI data dictionary](https://geminimedicine.ca/wp-content/uploads/2023/12/GEMINI-Data-Repository-Data-Dictionary-v3.0.2.html) contains more information about each of these variables.


<br></br>

Next, we will perform data quality/coverage checks and create our cohort. **The steps in the sections below are not strictly sequential!** Instead, data checks and cohort refinement typically go hand in hand based on an iterative process: We usually start with some basic data checks & exploration on the whole dataset, then apply cohort inclusion/exclusion steps, then check the data for cohort-specific issues, which may cause us to refine your inclusions/exclusions etc. ... Throughout this process, we may also derive additional variables, which should be included in the data checks to make sure all variables in the final cohort are ready to be analyzed.

Please also review this [Rgemini vignette](https://gemini-medicine.github.io/Rgemini/articles/plotting_data_exploration.html), which contains more details about some of the functions used below.


## Check data coverage

First, we'll check data coverage. Generally, this should be performed on the **whole dataset** within the relevant cohort period (2018-2020), prior to applying any additional inclusion/exclusion steps.

**Note:** We typically check coverage by plotting variables by hospital * discharge month (because GEMINI data are pulled based on patients' discharge dates).


### Number of encounters 

A basic sanity check is to plot the number of encounters per hospital per month:

```{r}
Rgemini::plot_over_time(data, func = "n")
```

<br></br>

<details>
<summary>***Please review this plot carefully and think about what information you can gather from it. Then expand this section for more information on things to consider.***</summary>

Plotting the number of encounters over time and by hospital can provide insights into:

**1) Data coverage:** Certain hospitals may not have any (administrative) data during certain time periods.

**2) Patient volume:** Some hospitals might have a very large/small number of encounters overall, which is important to consider for the analyses below (e.g., small community hospitals will generally contribute fewer encounters to the overall cohort than large academic hospitals).

**3) Changes in the cohort over time:** For example, you might observe sudden drops/increases in encounter numbers, which might be due to seasonal changes, COVID-related factors, changes in the GEMINI cohort definition (e.g., expansion from GIM to all-medicine), or potential biases introduced during cohort inclusion/exclusion steps (see below).

</details>


In our example data, we can see that sites 6, 9, 10, and 12 do not have any encounters during certain time periods, indicating gaps in data coverage. We will therefore exclude these sites to make sure we have consistent data timelines across all hospitals. 


<details>
<summary>***Expand this section for some additional tips***</summary>

There are situations where we might have retained encounters during hospital-time-periods where data were available (e.g., decide to include hospital 12 before the stark drop off instead of exclude hospital 12 altogether). The decision of how to handle missing hospital-time-periods comes down to the specific research question, and whether retaining those data will induce bias. If we are intersted in trends over time, exclusion is generally advised. NB this guidance also applied to **4.1.2 Clinical data coverage**

</details>

### Clinical data coverage 

Even if a hospital has a large number of encounters during certain time periods, this does not necessarily mean that GEMINI has *all* relevant variables for these encounters. This is particularly relevant for clinical data (e.g., lab/pharmacy/vitals/transfusions etc.), which may have low coverage for certain hospitals and time periods. Therefore, we should also check data coverage for any relevant clinical variables, or specific columns of interest that may have missing values. 

For example, in our analyses, we want to include mLAPS as a covariate. Since mLAPS relies on lab data, `mlaps` will be missing for any time periods where lab data were not available. To check this, we'll plot the % of encounters that have a missing `mlaps` value :

```{r, results='hide'}
Rgemini::plot_over_time(data, plot_var = "mlaps", func = "na")
```

<br></br>

This figure shows that hospitals 15 and 17 have a high percentage of missing mLAPS data during certain time periods. We will therefore exclude these 2 sites.

**Note:** For simplicity, here we assume that missing `mlaps` values are indeed due to time periods without lab data coverage (instead of potential mistakes in the derived `mlaps` variable or mapping issues). However, in general, you should verify this assumption and carefully review data coverage for each table using the `Rgemini::data_coverage()` function [**coming soon**].


## Apply cohort inclusions/exclusions

Next, we filter the cohort for all relevant encounters based on the inclusion/exclusion steps listed above. To facilitate this process, let's derive a flag for each `genc_id` indicating whether that encounter meets a given inclusion/exclusion criterion.

***Incl. 1: GIM encounters between 2018 - 2020***

In our case, this corresponds to all encounters in the dummy data.

```{r}
data[, incl1_gim := TRUE]
```

***Incl. 2: Hospitals with data coverage***

Here, we include all sites that passed the data coverage checks from the previous section: 

```{r}
data[, incl2_coverage := !hospital_num %in% c(6, 9, 10, 12, 15, 17)]
```


***Incl. 3: Pneumonia diagnosis***

In our dummy data, we will filter for entries where `ipdiagnosis_mrdx` (most responsible discharge diagnosis from inpatient diagnosis table) starts with J10-J18 ("Pneumonia"):

```{r}
data[, incl3_pneumonia := grepl("^J12|^J13|^J14|^J15|^J16|^J17|^J18", ipdiagnosis_mrdx)]
```

<details>
<summary>**Expand this section for additional considerations when filtering by ICD-10-CA codes**</summary>

**1) What diagnosis codes to include/exclude?** 
This is usually determined by an SME who will provide you with a list of relevant ICD-10-CA codes. In our example, all ICD-10-CA codes from J10-J18 should be included for pneumonia. Usually, you should filter for all diagnosis codes that **start** with the same characters (i.e., including children codes like "J12.8"), unless otherwise specified. If you are unsure, please clarify with the SME. 

**2) Is the diagnosis type relevant?** 
In our example, the cohort definition specifies "Pneumonia as a most responsible diagnosis code (MRDx)". We therefore need to filter by `diagnosis_type = M`. According to (HSMR methodology)[https://www.cihi.ca/sites/default/files/document/hospital-standardized-mortality-ratio-meth-notes-en.pdf] `diagnosis_type = 6` (Proxy MRDx) should also be included and takes priority over type-M.

**3) Do you only want to filter by in-patient diagnosis codes or also include ED diagnoses?**  
When filtering for a specific condition based on patient's MRDx, we typically only include in-patient diagnoses as they tend to be more reliable compared to ED diagnoses. However, this decision may be project specific, and in certain cases it might make sense to consider ED diagnoses to increase sensitivity. If you are unsure, please discuss this with the SME. 

</details>


<br></br>

***Excl. 1: Acute-care transfer in***

In our dummy `data` table, this is defined by `acute_transfer_in`, which is derived based on whether the `genc_id` has an entry in `lookup_transfers` where `acute_transfer_in = TRUE`:

```{r}
data[, excl1_transfer := acute_transfer_in]
```


***Excl. 2: Not admitted from ED***

In our dummy `data` table, this is defined by `admitted_from_er`, which is a flag indicating whether or not a given `genc_id` has an entry in the `er` table:

```{r}
data[, excl2_ed := !admitted_from_er]
```



Let's make sure there are no missing values in any of the derived inclusion/exclusion flags (missing values would indicate that certain flags can't be defined for some `genc_ids`, in which case you should carefully check all variables that are required for the cohort definition):


```{r}
Rgemini::n_missing(data[,.(incl1_gim, incl2_coverage, incl3_pneumonia, excl1_transfer, excl2_ed)])
```


&nbsp;

Here, we don't have any missing values in any of the inclusion/exclusion flags, so we can go ahead and build our cohort as follows: 

```{r echo = FALSE}
## Note: This will be added to Rgemini soon...
cohort_creation <- function(
    cohort,
    labels,
    exclusion_flag = NULL,
    show_prct = TRUE,
    group_var = NULL,
    ...) {

  ## if no exclusion flags provided, interpret all steps as "inclusions"
  if (is.null(exclusion_flag)) {
    exclusion_flag <- c(rep(FALSE, length(cohort)))
  }

  ## check user input
  Rgemini:::check_input(cohort, "list")
  Rgemini:::check_input(labels, "character")
  Rgemini:::check_input(list(exclusion_flag, show_prct), "logical")
  if (!is.null(group_var)) {
    Rgemini:::check_input(group_var, "charater")
  }

  if (length(cohort) != length(labels) | length(cohort) != length(exclusion_flag)) {
    stop("The `cohort`, `labels`, and `exclusion_flag` (if provided) inputs need to have the same length.")
  }

  create_cohort <- function(cohort, exclusion_flag, group_var, ...) {

    ## get number of rows at each cohort creation step (= usually number of unique genc_ids)
    N <- sapply(cohort, nrow)

    ## calculate change in N between steps
    cohort_tab <- data.table(N, previous_n = lag(N))
    cohort_tab[, `%` := 100 * N / previous_n]

    ## for any steps with exclusion_flag = TRUE, show removal as -n (-X%)
    cohort_tab[exclusion_flag == TRUE & !is.na(previous_n), N := -(previous_n - N)]
    cohort_tab[exclusion_flag == TRUE & !is.na(previous_n), `%` := -(100 - `%`)]

    ## combine N (%, if show_prct = TRUE)
    cohort_tab[, `N (%)` := ifelse(
      !is.na(`%`) & show_prct == TRUE, paste0(prettyNum(N, ...), " (", round(`%`, 1), "%)"), prettyNum(N, ...)
    )]
    cohort_tab <- cohort_tab[, .(`N (%)`)]

    ## add row with final cohort number
    # (only needed if last step was showing exclusion)
    if (exclusion_flag[length(exclusion_flag)] == TRUE) {
      cohort_tab <- rbind(
        cohort_tab,
        data.table(`N (%)` = prettyNum(nrow(cohort[[length(cohort)]]), ...))
      )
    }

    if (!is.null(group_var)) {
      if (length(unique(unique(cohort[[1]][[group_var]]))) == 1) {
        colnames(cohort_tab) <- paste(group_var, "=", as.character(unique(cohort[[1]][[group_var]])))
      }
    }

    return(cohort_tab)
  }


  ## create table for overall cohort
  cohort_tab <- create_cohort(cohort, exclusion_flag, group_var, ...)

  ## add columns by subgroup (if group_var specified)
  if (!is.null(group_var)) {
    groups <- unique(cohort[[1]][[group_var]])
    grouped_list <- list()
    for (i in groups) {
      grouped_list[[i]] <- lapply(cohort, function(x) x[get(group_var) == i])
    }
    cohort_tab_grouped <- lapply(
      grouped_list, create_cohort,
      exclusion_flag = exclusion_flag, group_var = group_var, ...
    )
    cohort_tab_grouped <- do.call(cbind, cohort_tab_grouped)
    cohort_tab <- cbind(cohort_tab, cohort_tab_grouped)
  }

  ## add column with inclusion/exclusion step number
  steps <- c(ifelse(
    exclusion_flag == TRUE,
    paste("Excl. ", ave(seq_along(exclusion_flag), exclusion_flag, FUN = seq_along), sep = ""),
    paste("Incl. ", ave(seq_along(exclusion_flag), exclusion_flag, FUN = seq_along), sep = "")
  ), if (exclusion_flag[length(exclusion_flag)] == TRUE) "")

  labels <- c(labels, if (exclusion_flag[length(exclusion_flag)] == TRUE) "Final cohort")

  cohort_tab <- cbind(
    steps,
    labels,
    cohort_tab
  )

  ## Fix column names
  colnames(cohort_tab)[1:3] <- c("", "Cohort creation step", ifelse(show_prct == TRUE, "N (%)", "N"))
  if (!is.null(group_var)) {
    colnames(cohort_tab)[3] <- paste("Overall", colnames(cohort_tab)[3])
  }

  return(cohort_tab)
}
```

```{r}
cohort_table <- cohort_creation(
  cohort = list(data[incl1_gim == TRUE], #  cohort (discharges between 2018 - 2020)
                data[incl2_coverage == TRUE],
                data[incl2_coverage == TRUE & incl3_pneumonia == TRUE],
                data[incl2_coverage == TRUE & incl3_pneumonia == TRUE & excl1_transfer == FALSE],
                data[incl2_coverage == TRUE & incl3_pneumonia == TRUE & excl1_transfer == FALSE & excl2_ed == FALSE]),
  labels = c("All GEMINI encounters discharged between Apr 2018 - March 2020",
             "Encounters from hospitals with high data coverage",
             "Encounters with Pneumonia MRDx",
             "Encounters with an acute-care transfer",
             "Encounters not admitted from the ED"
             ),
  exclusion_flag = c(FALSE, FALSE, FALSE, TRUE, TRUE),
  big.mark = ","
)

cohort_table %>% knitr::kable(escape = FALSE, format = "html") %>%
  kable_styling("hover") %>%
  row_spec(6,  bold = TRUE)

```


<br></br>

Let's create a new data table called `cohort` that only contains the eligible `genc_ids`: 

```{r}
cohort <- data[
  incl2_coverage == TRUE & 
  incl3_pneumonia == TRUE & 
  excl1_transfer == FALSE & 
  excl2_ed == FALSE
]
```

We should make sure the number of rows in this table corresponds to what's shown in the last row of the cohort creation table above:

```{r}
nrow(cohort)
```


## Check variable distributions & missingness in cohort

Now that we have created the cohort, we should plot some basic descriptive statistics to check the distribution & missingness of all relevant predictors/covariates and outcome variables.

```{r}
Rgemini::plot_summary(
  cohort[, .(age, gender, mlaps, admit_charlson_derived, los_days_derived, in_hospital_mortality_derived)]
)
```

&nbsp;


<details>
<summary>***Please review this plot carefully and think about what information you can gather from it. Then expand this section for more information.***</summary>

By plotting histograms/bar plots of all relevant cohort variables, we can gain insights into the following:

**1) % of entries with missing values:** In our dummy data, only `mlaps` has missing values (see section *4.3.1 Missing values*](#missing) for more details).

**2) Whether the variables are of the expected type (e.g., categorical vs. continuous):** For example, gender in CIHI data largely reflects biological sex, which is treated as a categorical variables with 3 levels (M/F/O).

**3) Whether continuous variables are within the expected range:** For example, in our case, all continuous variables should have values >= 0 (or >= 18 in the case of age) and Charlson Comorbidity Index should be an integer between 0-24. Length of stay has some extreme values (e.g., >365 days). Although these are no implausible (patients can be hospitalized for very long periods of time), we should carefully consider if these patients are part of our patient population of interest (see section *4.3.2 Considering extreme values*](#extreme)).  

**4) Whether continuous variables are normally distributed or skewed:** For example, length of stay is heavily right-skewed, which we should consider in our modelling decisions later on (see ***Regression model*** section below).


</details>

In the sections below, we will discuss missing values and outliers in more detail. 



### Missing values {#missing}

Let's first take a closer look at missing values. We need to carefully consider what the reason for missing values is in order to make an informed decision about how to deal with them.

<details>
<summary>***Consider what potential reasons could explain missing values in `mlaps`. Then expand this section for more information.***</summary>

`mlaps` is based on laboratory tests collected before a patient's `admission_date_time` (i.e., in the emergency department).  `mlaps` values are missing for any `genc_ids` that do not have any ED lab entries for relevant mLAPS tests. This could be due to the following reasons:

**1. The encounter was not admitted via the ED.** These encounters were excluded from our cohort, so this does not apply here.

**2. That hospital does not have lab data available for that encounter.** We already checked lab data coverage above and removed hospitals without continuous lab data. For the remaining time periods, `mlaps` missingness was generally low (<10%) so we can assume that lab data coverage was generally high.

**3. Tests were not performed.** If we can rule out 1) and 2), the reason for why individual `genc_ids` don't have an `mlaps` value is likely because testing was not indicated for these particular encounters (e.g., when the patient was admitted, the physician did not order any tests included in the `mlaps` calculation because they were not deemed clinically necessary). 

</details>

In our case, the main plausible reason for missing `mlaps` is that testing was not indicated for `genc_ids` with missing `mlaps`. We will therefore impute missing `mlaps` with 0 here (i.e., we assume that the encounter likely would have had normal results on all relevant mLAPS tests):

```{r}
cohort[is.na(mlaps), mlaps := 0]
```


**Note that it's important to distinguish between "data coverage" (overall data volume for certain tables) vs. "missing values" (individual entries with `NA` values for certain table columns).** Even when data coverage is generally high, individual entries may still have missing values. For time periods with high data coverage, we can sometimes make certain assumptions about missing values based on the clinical context, allowing us to perform single-value imputation (e.g., imputing all missing `mlaps` values with 0). There are many cases where we cannot make these assumptions. Make sure to discuss how you handle missing values with your PI and Scientific Advisor. 

<details>
<summary>***Expand this section to learn more about different types of missingness.***</summary>

In our scenario, missingness of `mlaps` represents an example of systematic missingness - also referred to as **"missing not at random" (MNAR)**. This means that the missingness is directly related to other predictor variables (e.g., patients' illness severity) and/or outcomes (e.g., in-hospital death). 

In other scenarios, values might be **missing at random (MAR)**. In that case, we should not perform single-value imputation. Instead, we may decide to use a complete-case analyses (i.e., only include encounters without missing values) or performing multiple imputation. See [here](https://onlinecjc.ca/article/S0828-282X(20)31111-9/fulltext#:~:text=Missing%20data%20is%20a%20common,all%20subjects%20in%20the%20sample) for a more detailed discussion on this.

</details>


### Considering extreme values {#extreme}

In the summary plot above, we can see that there are some encounters with extremely long length of stay (LOS). Let's check what percentage of encounters have a length of stay longer than 90 days:

```{r}
100 * sum(cohort$los_days_derived > 90) / nrow(cohort)
```
Only ~0.5% of patients in our cohort stayed in hospital for more than 90 days. These patients are not representative of the typical pneumonia patient we are interested in. There is an element of complexity to their situation that makes them different than the typical pneumonia patients (maybe they are sicker, maybe they lack social supports to be discharged elsewhere, etc.). Further, our baseline covariates like `mlaps` are measured at the time of admission, but for patients with long LOS, several other events may occur throughout their hospitalization, which can affect clinical outcomes (in fact, patients with long LOS may have been admitted with a different condition, but then contracted pneumonia during their hospitalization, which was ultimately coded as their MRDx). 

To remove any bias these outliers might introduce in the model, we will exclude any encounters with long LOS. Here, we choose LOS <= 90 days as a cut-off, but in general, you should discuss the appropriate criterion with a clinical expert. This will be informed by the nature of the research question. 

```{r}
data[, exclude_los := los_days_derived > 90]

cohort_table <- cohort_creation(
  cohort = list(data[incl1_gim == TRUE], # baseline cohort (discharges between 2018 - 2020)
                data[incl2_coverage == TRUE],
                data[incl2_coverage == TRUE & incl3_pneumonia == TRUE],
                data[incl2_coverage == TRUE & incl3_pneumonia == TRUE & excl1_transfer == FALSE],
                data[incl2_coverage == TRUE & incl3_pneumonia == TRUE & excl1_transfer == FALSE & excl2_ed == FALSE],
                data[incl2_coverage == TRUE & incl3_pneumonia == TRUE & excl1_transfer == FALSE & excl2_ed == FALSE & exclude_los == FALSE]),
  labels = c("All GEMINI encounters discharged between Apr 2018 - March 2020",
             "Encounters from hospitals with high data coverage",
             "Encounters with Pneumonia MRDx",
             "Encounters with an acute-care transfer",
             "Encounters not admitted from the ED",
             "Encounters with LOS > 90 days"
             ),
  exclusion_flag = c(FALSE, FALSE, FALSE, TRUE, TRUE, TRUE),
  big.mark = ","
)

cohort_table %>% knitr::kable(escape = FALSE, format = "html") %>%
  kable_styling("hover") %>%
  row_spec(7,  bold = TRUE)
```

Remember to update your `cohort` data table in line with the updated exclusion criteria: 

```{r}
cohort <- data[
  incl2_coverage == TRUE & 
    incl3_pneumonia == TRUE & 
    excl1_transfer == FALSE & 
    excl2_ed == FALSE & 
    exclude_los == FALSE # add new exclusion
]
```


**Note:** We generally do not recommend blindly removing outliers (e.g., based on generic criteria like +/-3 SDs) unless there is a conceptual rationale, or reasons to assume that outliers are implausible values that may reflect data quality issues (e.g., data entry errors). Instead, you should carefully consider what the potential reason for outliers is and whether they might affect the relationships between your variables of interest (e.g., see DAG above) in order to decide how to handle extreme values. 


### Variable transformation

During cohort generation, you will often need to create new derived variables, or perform additional preprocessing/transformations. For example, as shown in the plot above, `gender` is a categorical variable with 3 levels. Since `gender = "O"` is very rare and low cell counts represent a patient privacy issue, we will dichotomize this into a new variable "Female" vs. "Not female". We will also rename it into `sex_female` since CIHI data largely reflect biological sex, rather than gender: 

```{r}
cohort[, sex_female := gender == "F"]
```



## Final checks: Plot variables over time & by hospital

In the previous steps, we created the cohort and performed some data preprocessing. Let's plot our cohort variables over time (again) to check whether there are any weird time trends that may introduce biases. This is also a good way to double check whether any of our inclusion/exclusion steps may have introduced unexpected patterns in our data.

As an example, we'll just plot `mlaps` here again (but you should perform similar checks for all other relevant predictor/outcome variables). We would expect `mlaps` to remain fairly stable over time (with some noise). Since we already checked for lab data coverage, we would not expect there to be any time periods with missing entries:

```{r}
Rgemini::plot_over_time(cohort, plot_var = "mlaps", func = "mean")
```
  
**Note:** For the purpose of data exploration and data quality checks, it can often be helpful to plot means instead of medians. Because means are more sensitive to outliers than medians (see more details in the following section), it's often easier to detect unexpected trends/outliers when plotting the mean.



*  *  *  *

# Descriptive statistics

- Generate table1 and additional descriptive plots (but no outcome peeking)
- Double check that numbers match up across all variables
- Confirm that our cohort has sample size to support the analysis. 

```{r}

```


*  *  *  *

# Regression model

**This section is meant to walk you through more conceptual aspects of why we make certain decisions when analyzing these data. We will build starting from simple models to more complex. The step-wise format of this section is more data-driven than we would do in practice. The aim is to build up your intuition about different aspects of the final model, then in the next section we will present the analysis as we might do it for a resarch projcet.**

## Types of regression 

Regression is a statistical method used to model the relationship between a dependent variable (often called the outcome or response variable) and one or more independent variables (often called predictors or explanatory variables). The nature of the outcome variable is what determines the type regression we will use. This influences the kind of estimate we report. Note that these models can produce a wider variety of estimates than the table indicates (e.g. logistic regession can produce risk ratios), but these are the interpretations of the coefficients). 

```{r echo = FALSE}
regression_table <- data.frame(
  Regression_Type = c("Linear Regression", 
                     "Logistic Regression", 
                     "Poisson Regression", 
                     "Negative Binomial Regression", 
                     "Cox Proportional Hazards Regression", 
                     "Fine-Gray Regression"),
  Outcome_Type = c("Continuous", 
                   "Binary", 
                   "Count", 
                   "Overdispersed Count", 
                   "Time-to-Event", 
                   "Time-to-Event with Competing Risk"),
  Estimate_Type = c("Estimated Mean Difference", 
                  "Odds Ratio", 
                  "Rate Ratio", 
                  "Rate Ratio", 
                  "Hazard Ratio", 
                  "Subdistribution hazard ratio") 
)

# Create a table using kable()
kable(regression_table, 
      col.names = c("Regression Type", "Outcome Type", "Estimate Type"), 
      align = "l", 
      caption = "Regression Types and Corresponding Outcome Types")

```

## In-hospital mortality 
Let's understand the effect of age on in-hospital mortality. 

In-hospital mortality is binary (dead, not dead). So, we will use a logistic regression. We use the `rms` package [3](https://cran.r-project.org/web/packages/rms/index.html), which is a fantastic resource that makes best-practices easy to implement. 

A simple approach would be to fit a univariate logistic regression with mortality as the outcome and age as an independent variable. We fit that regression: 
```{r}
options(scipen = 999) # turns off scientific notation in outputs 
library(rms)


mod <- lrm(in_hospital_mortality_derived ~ age,
  data = cohort,
  x = TRUE, y = TRUE #this saves some data in model object for downstream use 
)
mod

odds_ratio <- data.frame(
  OR = exp(mod$coefficients),
  CIL95 = exp(mod$coefficients + qnorm(0.025) * sqrt(diag(mod$var))),
  CIU95 = exp(mod$coefficients + qnorm(0.975) * sqrt(diag(mod$var)))
) %>% round(3)
odds_ratio["age",]
```

We see that the odds ratio is 1.044 and the 95% confidence limits are 1.037 to 1.052. Each additional year of age is associated with 1.044 increased odds of death. Our 95%CI do not cross 1, so our results are statistically significant. 

This tells us that older age is associated with more death (1.044-fold increased odds per year), but it does not tell us how much death. Odds ratios are a relative measure of risk, not an absolute measure. For that, we turn to probabilities. Recall that odds are a transformation of probability. If something has a 75% probability (P=0.75), the odds that it happens are 3:1. `Odds = (probability / (1-probability))`.

The logistic regression models log(odds). Thus, predicted values from the logistic regression are in log(odds) units, which can be transformed to probabilities using the above formula. In this way, we can produce predicted probabilities to understand absolute risk. 

```{r}
dd <- datadist(cohort)
options(datadist = "dd") # these two lines are required when using Predict()

preds <- Predict(mod,
              conf.int = 0.95, 
              conf.type = "mean", 
              fun = plogis 
)

plot(preds, main = "Predicted probability of death by age")
```

We see from this plot that the predicted probability of death ranges from <0.1% in 18 year olds to nearly 20% in the oldest patients. This is new, interesting information. 

<details>
<summary>***Expand this section if you are confused as to why this plot appears nonlinear***</summary>
You may notice that this plot of predicted probabilities is nonlinear. Why is this the case? We mdoeled age as a linear term, so there is only one coefficient (the odds ratio) that describes the increase in odds of mortality for each additional year. So why does this relationship appear nonlinear? Remember that logistic regression treats the **log odds** as linear, and our transformation to probabilities involved an exponentiation. This is the source of the nonlinearity on the probability scale. See below proof of linearity on the log-odds scale. 

```{r}
preds <- Predict(mod,
              conf.int = 0.95, 
              conf.type = "mean"
)

plot(preds, main = "Log-odds of death by age")
```
</details>

So, now we have a single odds ratio that describes the increased odds of death per year. In reporting this single odds ratio, we are assuming that each year, the odds of death increase by the same amount as the previous year. We assume that an 18 year old turning 19 and an 89 year old turning 90 both confer the same additional odds of death. This is a strong assumption. Let's test it! 

We will fit a model that relaxes the linearity assumption on age. We will use a restricted cubic spline with 4 knots to do this. We compare model fit between linear age and nonlinear age. 

```{r}
mod_spl <- lrm(in_hospital_mortality_derived ~ rcs(age, 4),
        data = cohort,
         x = TRUE, y = TRUE 
)

lrtest(mod, mod_spl) # likelihood ratio test
AIC(mod)
AIC(mod_spl) # AIC no better for nonlinear
```

Note that linearity is a strong assumption that we often have no basis to make. In practice, we usually will go ahead and fit the spline if we have enough degrees of freedom to do so. The spline *allows* the relationship to be nonlinear, but can also fit a straight line if that's the shape of the association. If investigators are keen to report a single odds ratio, we would perform a test like the above to determine whether that is reasonable to do. 

See that the nonlinear model does not fit the data any better based on AIC and likelihood ratio test. This is consistent with the plot below, which shows very similar predicted probabilities using the spline.  

```{r}
preds <- Predict(mod_spl,
              conf.int = 0.95, 
              conf.type = "mean", 
              fun = plogis
)

plot(preds, main = "Predicted probability of death by age")
```


See that we now have 3 separate coefficients for age. These coefficients are essentially uninterpretable, which is a cost we pay for relaxing the nonlinearity assumption. We rely on likelihood ratio tests, predicted probabilities, and post-hoc contrasts to report results from splines. 
```{r}
mod_spl
```

Let's dig into why the spline can't be described by a single odds ratio. Here we compare two specific age values in the linear model. Nice that no matter which ages I pick, the increase in odds per year is 1.044.  
```{r}
summary(mod, age = c(20, 21)) 
summary(mod, age = c(60, 61))
summary(mod, age = c(90, 91))
```

Notice that the odds ratio in the spline depends on which age values I pick. You cannot summarize a spline with a single odds ratio, but you can pick points on the curve and calculate an odds ratio between them (as I've done below).
```{r}
summary(mod_spl, age = c(20, 21)) 
summary(mod_spl, age = c(60, 61))
summary(mod_spl, age = c(90, 91))
```

This comparison of the linear to non-linear model lets us know that assuming the odds ratio is constant across age (linear) is reasonable. Let's proceed under this assumption for now. We report this result to our hypothetical PI. 

The PI responds with: "Thanks for this analysis, but I think I need an updated analysis. I know that men are more likely to get pneumonia at younger ages, and men also don't live as long as women. I don't want this age effect to be driven by this confounding effect of sex."

We say "no problem, we will adjust the model for sex and report an odds ratio that holds constant the effect of sex."

```{r}
mod_adj <- lrm(in_hospital_mortality_derived ~ age + sex_female,
        data = cohort,
         x = TRUE, y = TRUE 
)

odds_ratio <- data.frame(
  OR = exp(mod_adj$coefficients),
  CIL95 = exp(mod_adj$coefficients + qnorm(0.025) * sqrt(diag(mod_adj$var))),
  CIU95 = exp(mod_adj$coefficients + qnorm(0.975) * sqrt(diag(mod_adj$var)))
) %>% round(3)
odds_ratio[2:3,]
```

We see that the odds ratio is 1.045 (95%CI 1.037-1.053). We can tell the PI that the effect remains of a simialr magnitude after adjustment for sex. 

We also notice that the odds ratio for female sex is 0.837 (95%CI 0.693-1.010). That is, the effect of female sex holding age constant! This last bit is critical to the interpreation of the adjusted odds ratio. This interpretation of "holding X constant" extends to when we adjust for multiple variables. "The effect of age on death, holding constant A, B, C, D, ...". Please read this paper about important aspects of interpreting regression results: https://academic.oup.com/aje/article-abstract/177/4/292/147738?redirectedFrom=fulltext. Directed acyclic graphs (DAGs) described earlier in this document are central to the interpretation of multivariable regession 


Now we discuss a consideration you will make in almost every GEMINI analysis - how to handle nesting (i.e., clustering). GEMINI data include hospitalizations nested within patients, patients nested within physicians, physicians nested within hospitals. This nesting causes the data to be correlated (e.g., there are similarities between patients and processes of care within a each hospital), which violates a central regression assumption: ***independence***. 

Unfortunatley, regression methods are unable to practically handle all of these types of nesting - so we need to prioritize. The PI needs to decide which types of nesting are most important to consider for a given research question. This prioritization is beyond the scope of this section, but please make sure to discuss with your Scientific Advisor. Hospital is the most common form of nesting we account for based on the kinds of research questions we analyze.  

You present the updated results to the PI with sex incorporated, and you bring this point up about nesting to the PI. Your PI responds "Well, the unit of analysis we're using is the hospitalization (i.e., genc_id). There may be hospital-specific practices that affect in-hospital death, and also the patients are quite different at different hospitals. Let's make sure we consider the nesting of hospitalizations within hospitals."

You say "Alright, what about nesting of hospitalizations within patients? Would you like me to consider that?"

PI replies "No it's alright. I'm comfortable thinking about each hospitalization as a distinct opportunity to pass away. My research aims to inform hospital policy, and I think it's reasonable to conceive of each hospitalization as distinct from the hospital's perspective. If reviewers push us, we can randomly select one hospitalization and present that as a sensitivity analysis."

You say "OK. Sounds like you have a good justification and have thought this through. Will you consider the nesting of physicians within hospitals?"

PI replies "Good question. I conceptualize a physician effect in terms of: a) physician-level differences (physicians practice differently from one another); and b) hospital-level effects (policy and process at your hospital can really influence how a physician provides care)". You and I already agreed to account for the hospital effects. I don't think physician-level effects are a priority for us to consider because [...]. We can think about it more and, if necessary, report this as a limitation in the research paper."

The above is an artificially straightforward conversation with the PI. The PI will often need you to ask probing questions for you to undertsand the best way to handle nesting. They may also need you to explain the different options, their interpretations, and their limitations. This is why it's important for you to have a strong understanding of different ways to account for this nesting and when to apply each. In practice, your Scientific Advisor will support you in this conversation. 


You go back to update the analysis to account for nesting of hospitalizations within patients, but then you realize you forgot to discuss *how* you will account for this nesting. Gah! There are important considerations! 

You send your PI an email: "Dear PI, We are able to account for hospital-level nesting using using cluster-robust standard errors, generalized estimating equations, or generalized linear mixed effects models. Would you please confirm which approach you would like us to use? Best, Me."

Pi replies: "Dear You, I do not know how to answer this. Please explain to me so I can make an informed decision. Alternatively please tell me what to choose and please write this part into methods section of my research paper. Best, PI."


**Narrator switch** 

We will review cluster-robust standard errors, generalized estimating equations (GEE), and generalized liner mixed-effetcs modles (GLMER) as methods to account for nested data. Our example will focus on the PI's request to incorporate hospital-level clustering into the analysis. 

```{r}

# Cluster-robust SE 


# GEE 


#GLMER 
library(lme4)


```

WITHIN-CLUSTER INTERPRETATION OF GLMER, ILLUSTRATE W SIMPSON'S PARADOX. 

<details>
<summary>**Expand section to learn about restricted cubic splines**</summary>
-describe basis function, knots, degrees of freedom (more expensive)
- knots at quantiles, connected by cubic polynomials 
- restricted means we constrain to linearity in the extremes. 

</details>

<details>
<summary>**Expand section to learn more about odds and probability**</summary>
- DESCRIBE ODDS VS PROBABILITY (P/1-P) 
- LOGREG MODELS LOG ODDS, WHICH CAN BE TRANSFORMED TO PROBABILITY 
- ODDS RATIOS TELL YOU HOW MUCH MORE LIKELY AN EVENT IS TO OCCUR IN A GROUP, BUT OFTEN WE WAN TTO KNOW HOW LIKELY IN EACH GROUP AND NOT JUST HOW MUCH MORE (EXPLAIN THIS IN THE CONTEXT OF EVENT RATE)

</details>


- Fit a-priori regression models (informed by question & variable types -> decision tree illustrating different variable types and appropriate models)
- Verify regression model assumptions are met 
- Link to resources on hypothesis testing (e.g., how to interpret p-values correctly, correcting for multiple comparisons, p-hacking etc.)
- center/standardize predictors?

```{r}

```

- Do whatever other analyses (subgroups?) 
- Wherever you can, functionalize your code if you are doing the same thing over and over again 

```{r}

```


*  *  *  *

# Result visualization & interpretation

- Identify important plots, make those plots 
- Think about uncertainty (do my estimates have measure of uncertainty? If not, find way to calculate SE.)
- Check results against my intuition about what they should be, spot check randomly like this 
- Incorporate results back into the clinicianâ€™s conceptual framework so I can explain the results in their language and emphasize things that matter to them, and downplay things they donâ€™t need to understand [iterative] 

```{r}

```


*  *  *  *

# References & resources

- Missing data: https://onlinecjc.ca/article/S0828-282X(20)31111-9/fulltext#:~:text=Missing%20data%20is%20a%20common,all%20subjects%20in%20the%20sample
- Introduction to regression analyses: https://bookdown.org/rwnahhas/RMPH/





