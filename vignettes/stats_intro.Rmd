---
title: "Introduction to statistical analyses with GEMINI data"
output:
  html_vignette:
    number_sections: true
    toc: true
    toc_depth: 3
    dfprint: kable

vignette: >
  %\VignetteIndexEntry{Statistics - Introduction}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}

---

```{r include = FALSE}

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5,
  warning = FALSE,
  message = FALSE
)

library(data.table)
library(tidyverse)
library(dplyr)
library(Rgemini)
library(lubridate)
library(kableExtra)

#rmarkdown::render("~/GitHub/Rgemini/vignettes/stats_intro.Rmd", output_dir = "/mnt/nfs/projects/research_projects/Rgemini/stats_vignette/")

```


*  *  *  *


# Introduction & overview

This vignette illustrates an example analysis with (dummy) GEMINI data. The goal of this vignette is to provide an educational resource for analysts to make informed decisions at each analysis step. Throughout the vignette, we also provide links to existing resources with more detailed explanations.

If you would like to discuss any topics in more detail, please use the [Rgemini discussion forum](https://github.com/GEMINI-Medicine/Rgemini/discussions/categories/statistics)


*  *  *  *

# Research question & conceptual model 

In this tutorial, we will consider a hypothetical research study to investigate the question:

> **What is the effect of patients' age on clinical outcomes, in-hospital mortality, length of stay (LOS), among patients with pneumonia discharged between 2018 - 2020?**. 


## Study design

As a general first step in conducting a research study, researchers would carefully consider the study design most suitable for answering the research question. Although analysts typically do not come up the study design themselves, knowing the fundamentals of study designs would help in effective understanding of research proposals and communicating with PIs and other researchers. 

<br></br>
<details>
<summary>**Expand section to learn about study designs and data considerations**</summary>

- The choice of study design is critical as it sets the framework for conducting the research, directs the analysis method, and influences robustness and validity of the study findings. For example, a cohort study provides stronger evidence for causal relationships than a case-control study. 

- Below is a brief sketch of the core designs in clinical research. Check out these resources for a refresher on core study designs: [1](https://www.ncbi.nlm.nih.gov/books/NBK470342/), [2](https://doi.org/10.1016/S0140-6736(02)07283-5). Of note, although there are general core study designs, designs and their categorizations are not rigid, and there are more complex designs and grey areas that may not clearly distinguish one design from another.

```{r, echo=FALSE, out.width = "40%", fig.align = "center", fig.cap="Figure 1. Common Study Designs. <span style='color:grey; font-size:11px'> ([Grimes DA and Schulz KF. The Lancet, 2002](https://doi.org/10.1016/S0140-6736(02)07283-5)) </span> " }
knitr::include_graphics("figures/stat_vignette_study_design.png", dpi = 200)
```


- Clearly, the choice of study design is dependent on the nature of the data being used. 

  + In experimental studies, data collection is driven by specific research questions (researchers have control over participant recruitment, intervention assignment and measurements collection). 
  + In contrast, GEMINI data are sourced from **routine data** collected on the basis of hospital admissions primarily for administrative and clinical purposes, not tailored to answering any specific research question. 
  
  > <span style='font-size:12px'> **Routine data**: A major source of GEMINI data is routinely collected electronic health records (EHR). Thus, our data shares similar characteristics and considerations as other EHR-derived databases when conducting research. This topic is beyond the scope of this tutorial. You are encouraged to check out these review articles [1](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6724703/), [2](https://pubmed.ncbi.nlm.nih.gov/38273982/), [3](https://dcricollab.dcri.duke.edu/sites/NIHKR/KR/Acquiring%20and%20Using%20Electronic%20Health%20Record%20Data.pdf) for a general overview of using EHR-derived data for research (e.g. common terminology, data attributes, study designs, advantages and limitations. Note that these articles were written in a US setting but the discussed concepts are generally applicable). </span>

  + The nature of routine data makes GEMINI data particularly suitable for conducting **observational studies**. Below are some example observational studies conducted using GEMINI data:
    + Retrospective cohort: <span style='font-size:11px'> [Bai AD et al. CHEST, 2024](https://doi.org/10.1016/j.chest.2023.08.008). [McIntyre MT et al. CMAJ, 2023](https://doi.org/10.1503/cmaj.221732). [Doshi S et al. JAMA Intern Med., 2023](https://doi.org/10.1001/jamainternmed.2023.2629).</span>
    + Cross-sectional: <span style='font-size:11px'>[Razak F et al. CMAJ Open, 2020](https://doi.org/10.9778/cmajo.20200098), [Verma AA et al. CMAJ Open, 2019](https://doi.org/10.9778/cmajo.20180181)</span>
    + Other designs are possible (e.g. methodology, machine learning etc), see [GEMINI publications](https://geminimedicine.ca/publications/)

</details>
<br></br>

With knowledge about study designs and GEMINI data characteristics, letâ€™s determine which study design would be suitable for addressing our research question.

- The exposure of interest is patient's age at admission. The outcomes of interest are in-hospital mortality and LOS.

- Experimental studies are not possible for this question (impossible for researchers to manipulate the exposure variable, age). The question is **observational** by nature, which is well suited for using GEMINI data.

- The question is looking to estimate the association (magnitude and direction) between patient's age at admission and their clinical outcomes. An analytical study rather than a descriptive study is required. Since in-hospital mortality and LOS can only be known after hospital admission, the temporal relationship between exposure and outcome is implied. Therefore, our research question calls for a **cohort study design**, which means that researchers would assemble a cohort of patients based on characteristics at admission (e.g. pneumonia) and then follow them over time for the occurrence of outcomes.

- As the outcomes of interest have already occurred upon data extraction, the cohort is considered retrospective.

- Therefore, a **retrospective cohort study** would be suitable for addressing the research question.


# Conceptaulizing the Research Question

## Directed Acyclic Graphs
A visual, conceptual model can help understand the research question and how its components are related to one another. A directed acyclic graph (DAG) is a graphical representation of the relationship between the outcome, exposure, and related variables: [Digitale JC et al. J Clin Epidemiol, 2022](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8821727/). It can be helpful in picking a statistical model by 'drawing' out the assumptions between variables. The following DAG shows a simple theoretical causal relationship between age, the exposure variable, and in-hospital mortality, one of the outcomes of interest. 

```{r, echo=FALSE, out.width = "60%", fig.align = "center", fig.cap="<span style='color:grey; font-size:11px'> DAG of age and in-hospital mortality</span> " }
knitr::include_graphics("H://repos/Rgemini/vignettes/figures/dag_img1.png", dpi = 200)
```

<br></br>
<details>
<summary>**Expand section to learn more about DAGs**</summary>
- In a DAG, causal relationships are always unidirectional (i.e. age can be a cause of in-hospital mortality, but not the reverse). Two causal relationships following each other form a path.
- There are common ways of describing the relationship between nodes (i.e. variables): 1) parent and children (direct relationship), 2) descendants and ancestors (any node along the path to or from another node)
- A directed path describes a causal relationship between two nodes
- An indirect path describes a confounding relationship between two nodes
- For more information, check out these resources: [DAGs: A simple introduction with simulations in R](https://arelbundock.com/posts/acmq_en_06_dag/), [Applications of DAGs in Causal Inference](https://www.r-bloggers.com/2018/08/applications-of-dags-in-causal-inference/)
</details>

## Third Variables
While it is possible to estimate the effect of age on mortality on its own, often called an unadjusted model, it is common practice to control for variables that could have a direct or indirect cause on the exposure and outcome. These variables are called confounders (also referred to as covariates) and controlling for these variables debiases the association between the variables of interest: [Wysocki A et al. Adv Meth Pract Pyschol Sci, 2022](https://journals.sagepub.com/doi/10.1177/25152459221095823#:~:text=After%20outlining%20a%20causal%20structure,of%20the%20predictor%20and%20outcome). 

  - Gender can affect the age that one acquires pneumonia, along with the severity of illness            experienced when pneumonia is acquired: [Corica B et at. Intern   Emerg Med, 2022](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9294783/).
  - Charlson comorbidities are comorbid conditions that can be used to predict the risk of death and     should be controlled for when considering the outcome of death: [Charlson ME et al. J Chronic Dis, 1987](https://www.sciencedirect.com/science/article/abs/pii/0021968187901718).
  - mLAPS (modified laboratory acute physiology score) is an indicator of illness severity based on physiological lab data at or before admission  that is used to adjust for risk: [Roberts S et al. Preprint, 2023](https://www.medrxiv.org/content/10.1101/2023.01.06.23284273v1). GEMINI's in-house package, [Rgemini](https://gemini-medicine.github.io/Rgemini/reference/mlaps.html), is a fast and convenient way of deriving this variable.

Including all variables in a statistical model is referred to as an adjusted model and can help better understand the causal relationship between an exposure and its outcome. The DAG below takes these variables into account. 
```{r, echo=FALSE, out.width = "60%", fig.align = "center", fig.cap="<span style='color:grey; font-size:11px'> DAG of age and in-hospital mortality, including confounders </span> " }
knitr::include_graphics("H://repos/Rgemini/vignettes/figures/dag_img2.png", dpi = 200)
```

Confounders are not the only variables that can affect the relationship between age and in-hospital mortality or LOS. Mediators, or intermediate variables, lie in the causal pathway between the exposure variable and outcome. In this analysis, a mediator would be caused by age and is a cause of the outcome variables. This type of analysis, mediation analysis, is beyond the scope of this study, but it is important to understand the distinction between controlling for a confounder that could bias results, and including mediators that block the path to an outcome: [MacKinnon D. Res Soc Work Pract, 2011](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3366634/)


Based on the conceptual model discussed above, we will define our cohort as follows:

+ **Inclusion steps**
  - Incl. 1: All GIM encounters discharged between Apr 2018 - Apr 2020
  - Incl. 2: Hospitals with high data coverage for relevant variables (here: administrative & lab data for `mlaps`)
  - Incl. 3: Encounters with Pneumonia as most responsible diagnosis code (MRDx)

+ **Exclusion steps:**
  - Excl. 1: Encounters transferred from another acute-care institute 
  - Excl. 2: Encounters not admitted from ED
  
The reason for the two exclusion steps is to make sure that any covariates we include as baseline characteristics (e.g., `mlaps` at admission) accurately reflect patients' condition when they first entered the hospital (rather than having received prior treatment at another healthcare facility they were transferred from). 


<details>
<summary>***Expand this section for some additional tips***</summary>

The cohort inclusion/exclusion steps should be developed in close collaboration between the clinical researcher and data analyst. Typically, the steps will need to be refined during the project kick-off meeting to make sure the specific criteria, sequence, and rationale for the cohort definition makes sense. The cohort creation steps may also need to be refined once the analyst has completed the data checks (see next section), which might reveal unforeseen challenges/data issues.

</details>

*  *  *  *

# Data checks & cohort generation

Now that we have clarified the conceptual framework and cohort definition, let's take a look at the data.

Here, we assume our baseline cohort consists of all GIM encounters discharged between Apr 2018 - Apr 2020 (see incl. 1 above) from 20 hospitals. GIM encounters are defined as all encounters that were either admitted to/or discharged from GIM (see `gim_flag_derived` in the `derived_variables` table [**NOTE: This will be added to the next DB version**]).

We'll load this dummy data from a saved file and turn it into a `data.table` object:

```{r}
# read sample data
data <- readRDS("/mnt/nfs/projects/research_projects/Rgemini/stats_vignette/dummy_data_stats.rds") %>% 
  data.table()
```


Next, we will perform some data quality/coverage checks and create our cohort. **The steps in the sections below are not strictly sequential!** Instead, data checks and cohort refinement typically go hand in hand based on an iterative process: We usually start with some basic data checks & exploration on the whole dataset, then apply cohort inclusion/exclusion steps, then check the data for cohort-specific issues, which may cause us to refine your inclusions/exclusions etc. ... Throughout this process, we may also derive additional variables, which should be included in the data checks to make sure all variables in the final cohort are ready to be analyzed.

Please also review this [Rgemini vignette](https://gemini-medicine.github.io/Rgemini/articles/plotting_data_exploration.html), which contains more details about some of the functions used below.


## Check data coverage

First, we'll check data coverage. Generally, this should be performed on the **whole dataset** within the relevant cohort period (2018-2020), prior to applying any additional inclusion/exclusion steps.

**Note:** We typically check coverage by plotting variables by hospital * discharge month (because GEMINI data are pulled based on patients' discharge dates).


### Number of encounters 

A basic sanity check is to plot the number of encounters per hospital per month:

```{r}
Rgemini::plot_over_time(data, func = "n")
```

<br></br>

<details>
<summary>***Please review this plot carefully and think about what information you can gather from it. Then expand this section for more information on things to consider.***</summary>

Plotting the number of encounters over time and by hospital can provide insights into:

**1) Data coverage:** Certain hospitals may not have any (administrative) data during certain time periods.

**2) Patient volume:** Some hospitals might have a very large/small number of encounters overall, which is important to consider for the analyses below (e.g., small community hospitals will generally contribute fewer encounters to the overall cohort than large academic hospitals).

**3) Changes in the cohort over time:** For example, you might observe sudden drops/increases in encounter numbers, which might be due to seasonal changes, COVID-related factors, changes in the GEMINI cohort definition (e.g., expansion from GIM to all-medicine), or potential biases introduced during cohort inclusion/exclusion steps (see below).

</details>


In our example data, we can see that sites 6, 9, 10, and 12 do not have any encounters during certain time periods, indicating gaps in data coverage. We will therefore exclude these sites to make sure we have consistent data timelines across all hospitals.


### Clinical data coverage 

Even if a hospital has a large number of encounters during certain time periods, this does not necessarily mean that GEMINI has *all* relevant variables for these encounters. This is particularly relevant for clinical data (e.g., lab/pharmacy/vitals/transfusions etc.), which may have low coverage for certain hospitals and time periods. Therefore, we should also check data coverage for any relevant clinical variables, or specific columns of interest that may have missing values. 

For example, in our analyses, we want to include mLAPS as a covariate. Since mLAPS relies on lab data, `mlaps` will me missing for any time periods where lab data were not available. To check this, we'll plot the % of encounters that have a missing `mlaps` value :

```{r, results='hide'}
Rgemini::plot_over_time(data, plot_var = "mlaps", func = "na")
```

<br></br>

This figure shows that hospitals 15 and 17 have a high percentage of missing mLAPS data during certain time periods. We will therefore exclude these 2 sites.

**Note:** For simplicity, here we assume that missing `mlaps` values are indeed due to time periods without lab data coverage (instead of potential mistakes in the derived `mlaps` variable or mapping issues). However, in general, you should verify this assumption and carefully review data coverage for each table using the `Rgemini::data_coverage()` function [**coming soon**].


## Apply cohort inclusions/exclusions

Next, we filter the cohort for all relevant encounters based on the inclusion/exclusion steps listed above. To facilitate this process, let's derive a flag for each `genc_id` indicating whether that encounter meets a given inclusion/exclusion criterion.

***Incl. 1: GIM encounters between 2018 - 2020***

In our case, this corresponds to all encounters in the dummy data.

```{r}
data[, incl1_gim := TRUE]
```

***Incl. 2: Hospitals with data coverage***

Here, we include all sites that passed the data coverage checks from the previous section: 

```{r}
data[, incl2_coverage := !hospital_num %in% c(6, 9, 10, 12, 15, 17)]
```


***Incl. 3: Pneumonia diagnosis***

In our dummy data, we will filter for entries where `ipdiagnosis_mrdx` (most responsible discharge diagnosis from inpatient diagnosis table) starts with J10-J18 ("Pneumonia"):

```{r}
data[, incl3_pneumonia := grepl("^J12|^J13|^J14|^J15|^J16|^J17|^J18", ipdiagnosis_mrdx)]
```

<details>
<summary>**Expand this section for additional considerations when filtering by ICD-10-CA codes**</summary>

**1) What diagnosis codes to include/exclude?** 
This is usually determined by an SME who will provide you with a list of relevant ICD-10-CA codes. In our example, all ICD-10-CA codes from J10-J18 should be included for pneumonia. Usually, you should filter for all diagnosis codes that **start** with the same characters (i.e., including children codes like "J12.8"), unless otherwise specified. If you are unsure, please clarify with the SME. 

**2) Is the diagnosis type relevant?** 
In our example, the cohort definition specifies "Pneumonia as a most responsible diagnosis code (MRDx)". We therefore need to filter by `diagnosis_type = M`. According to (HSMR methodology)[https://www.cihi.ca/sites/default/files/document/hospital-standardized-mortality-ratio-meth-notes-en.pdf] `diagnosis_type = 6` (Proxy MRDx) should also be included and takes priority over type-M.

**3) Do you only want to filter by in-patient diagnosis codes or also include ED diagnoses?**  
When filtering for a specific condition based on patient's MRDx, we typically only include in-patient diagnoses as they tend to be more reliable compared to ED diagnoses. However, this decision may be project specific, and in certain cases it might make sense to consider ED diagnoses to increase sensitivity. If you are unsure, please discuss this with the SME. 

</details>


<br></br>

***Excl. 1: Acute-care transfer in***

In our dummy `data` table, this is defined by `acute_transfer_in`, which is derived based on whether the `genc_id` has an entry in `lookup_transfers` where `acute_transfer_in = TRUE`:

```{r}
data[, excl1_transfer := acute_transfer_in]
```


***Excl. 2: Not admitted from ED***

In our dummy `data` table, this is defined by `admitted_from_er`, which is a flag indicating whether or not a given `genc_id` has an entry in the `er` table:

```{r}
data[, excl2_ed := !admitted_from_er]
```



Let's make sure there are no missing values in any of the derived inclusion/exclusion flags (missing values would indicate that certain flags can't be defined for some `genc_ids`, in which case you should carefully check all variables that are required for the cohort definition):


```{r}
Rgemini::n_missing(data[,.(incl1_gim, incl2_coverage, incl3_pneumonia, excl1_transfer, excl2_ed)])
```


&nbsp;

Here, we don't have any missing values in any of the inclusion/exclusion flags, so we can go ahead and build our cohort as follows: 

```{r echo = FALSE}
## Note: This will be added to Rgemini soon...
cohort_creation <- function(
    cohort,
    labels,
    exclusion_flag = NULL,
    show_prct = TRUE,
    group_var = NULL,
    ...) {

  ## if no exclusion flags provided, interpret all steps as "inclusions"
  if (is.null(exclusion_flag)) {
    exclusion_flag <- c(rep(FALSE, length(cohort)))
  }

  ## check user input
  Rgemini:::check_input(cohort, "list")
  Rgemini:::check_input(labels, "character")
  Rgemini:::check_input(list(exclusion_flag, show_prct), "logical")
  if (!is.null(group_var)) {
    Rgemini:::check_input(group_var, "charater")
  }

  if (length(cohort) != length(labels) | length(cohort) != length(exclusion_flag)) {
    stop("The `cohort`, `labels`, and `exclusion_flag` (if provided) inputs need to have the same length.")
  }

  create_cohort <- function(cohort, exclusion_flag, group_var, ...) {

    ## get number of rows at each cohort creation step (= usually number of unique genc_ids)
    N <- sapply(cohort, nrow)

    ## calculate change in N between steps
    cohort_tab <- data.table(N, previous_n = lag(N))
    cohort_tab[, `%` := 100 * N / previous_n]

    ## for any steps with exclusion_flag = TRUE, show removal as -n (-X%)
    cohort_tab[exclusion_flag == TRUE & !is.na(previous_n), N := -(previous_n - N)]
    cohort_tab[exclusion_flag == TRUE & !is.na(previous_n), `%` := -(100 - `%`)]

    ## combine N (%, if show_prct = TRUE)
    cohort_tab[, `N (%)` := ifelse(
      !is.na(`%`) & show_prct == TRUE, paste0(prettyNum(N, ...), " (", round(`%`, 1), "%)"), prettyNum(N, ...)
    )]
    cohort_tab <- cohort_tab[, .(`N (%)`)]

    ## add row with final cohort number
    # (only needed if last step was showing exclusion)
    if (exclusion_flag[length(exclusion_flag)] == TRUE) {
      cohort_tab <- rbind(
        cohort_tab,
        data.table(`N (%)` = prettyNum(nrow(cohort[[length(cohort)]]), ...))
      )
    }

    if (!is.null(group_var)) {
      if (length(unique(unique(cohort[[1]][[group_var]]))) == 1) {
        colnames(cohort_tab) <- paste(group_var, "=", as.character(unique(cohort[[1]][[group_var]])))
      }
    }

    return(cohort_tab)
  }


  ## create table for overall cohort
  cohort_tab <- create_cohort(cohort, exclusion_flag, group_var, ...)

  ## add columns by subgroup (if group_var specified)
  if (!is.null(group_var)) {
    groups <- unique(cohort[[1]][[group_var]])
    grouped_list <- list()
    for (i in groups) {
      grouped_list[[i]] <- lapply(cohort, function(x) x[get(group_var) == i])
    }
    cohort_tab_grouped <- lapply(
      grouped_list, create_cohort,
      exclusion_flag = exclusion_flag, group_var = group_var, ...
    )
    cohort_tab_grouped <- do.call(cbind, cohort_tab_grouped)
    cohort_tab <- cbind(cohort_tab, cohort_tab_grouped)
  }

  ## add column with inclusion/exclusion step number
  steps <- c(ifelse(
    exclusion_flag == TRUE,
    paste("Excl. ", ave(seq_along(exclusion_flag), exclusion_flag, FUN = seq_along), sep = ""),
    paste("Incl. ", ave(seq_along(exclusion_flag), exclusion_flag, FUN = seq_along), sep = "")
  ), if (exclusion_flag[length(exclusion_flag)] == TRUE) "")

  labels <- c(labels, if (exclusion_flag[length(exclusion_flag)] == TRUE) "Final cohort")

  cohort_tab <- cbind(
    steps,
    labels,
    cohort_tab
  )

  ## Fix column names
  colnames(cohort_tab)[1:3] <- c("", "Cohort creation step", ifelse(show_prct == TRUE, "N (%)", "N"))
  if (!is.null(group_var)) {
    colnames(cohort_tab)[3] <- paste("Overall", colnames(cohort_tab)[3])
  }

  return(cohort_tab)
}
```

```{r}
cohort_table <- cohort_creation(
  cohort = list(data[incl1_gim == TRUE], # baseline cohort (discharges between 2018 - 2020)
                data[incl2_coverage == TRUE],
                data[incl2_coverage == TRUE & incl3_pneumonia == TRUE],
                data[incl2_coverage == TRUE & incl3_pneumonia == TRUE & excl1_transfer == FALSE],
                data[incl2_coverage == TRUE & incl3_pneumonia == TRUE & excl1_transfer == FALSE & excl2_ed == FALSE]),
  labels = c("All GEMINI encounters discharged between Apr 2018 - March 2020",
             "Encounters from hospitals with high data coverage",
             "Encounters with Pneumonia MRDx",
             "Encounters with an acute-care transfer",
             "Encounters not admitted from the ED"
             ),
  exclusion_flag = c(FALSE, FALSE, FALSE, TRUE, TRUE),
  big.mark = ","
)

cohort_table %>% knitr::kable(escape = FALSE, format = "html") %>%
  kable_styling("hover") %>%
  row_spec(6,  bold = TRUE)

```


<br></br>

Let's create a new table called `cohort` that only contains the included `genc_ids`: 

```{r}
cohort <- data[
  incl2_coverage == TRUE & 
  incl3_pneumonia == TRUE & 
  excl1_transfer == FALSE & 
  excl2_ed == FALSE
]
```

We should make sure the number of rows in this table corresponds to what's shown in the last row of the cohort creation table above:

```{r}
nrow(cohort)
```


## Check variable distributions & missingness in cohort

Now that we have created the cohort, we should plot some basic descriptive statistics to check the distribution & missingness of all relevant predictors/covariates and outcome variables.

```{r}
Rgemini::plot_summary(
  cohort[, .(age, gender, mlaps, admit_charlson_derived, los_days_derived, in_hospital_mortality_derived)]
)
```

&nbsp;


<details>
<summary>***Please review this plot carefully and think about what information you can gather from it. Then expand this section for more information.***</summary>

By plotting histograms/bar plots of all relevant cohort variables, we can gain insights into the following:

**1) % of entries with missing values:** In our dummy data, only `mlaps` has missing values (see next section).

**2) Whether the variables are of the expected type (e.g., categorical vs. continuous):** For example, gender in CIHI data largely reflects biological sex, which is treated as a categorical variables with 3 levels (M/F/O).

**3) Whether continuous variables are within the expected range:** For example, in our case, all continuous variables should have values >= 0 (or >= 18 in the case of age) and Charlson Comorbidity Index should be an integer between 0-24.

**4) Whether continuous variables are normally distributed or skewed:** For example, length of stay is heavily right-skewed, which we should consider in our modelling decision later on (see ***Regression model*** section below).

**5) Whether there are any outliers:** For example, in addition to being skewed, length of stay also has some extreme values (e.g., >365 days). 

</details>

In the sections below, we will discuss missing values and outliers in more detail. 



### Missing values

Let's first take a closer look at missing values. We need to carefully consider what the reason for missing values is in order to make an informed decision about how to deal with them.

<details>
<summary>***Consider what potential reasons could explain missing values in `mlaps`. Then expand this section for more information.***</summary>

For `mlaps`, values are missing for any `genc_ids` that do not have any ED lab entries for relevant mLAPS tests. This could be due to the following reasons:

**1. The encounter was not admitted via the ED.** These encounters were excluded from our cohort, so this does not apply here.

**2. GEMINI data does not have lab data available for that encounter.** We already checked lab data coverage above and removed hospitals without continuous lab data. For the remaining time periods, `mlaps` missingness was generally low (<10%) so we can assume that lab data coverage was generally high.

**3. Tests were not performed.** If we can rule out 1) and 2), the reason for why individual `genc_ids` don't have an `mlaps` value is likely because testing was not indicated for these particular encounters (e.g., when the patient was admitted, the physician did not order any tests included in the `mlaps` calculation because they were not deemed clinically necessary).

</details>

In our case, the main plausible reason for missing `mlaps` is that testing was not indicated for `genc_ids` with missing `mlaps`. We will therefore impute missing `mlaps` with 0 here (i.e., we assume that the encounter likely would have had normal results on all relevant mLAPS tests):

```{r}
cohort[is.na(mlaps), mlaps := 0]
```


**Note that it's important to distinguish between "data coverage" (overall data volume for certain tables) vs. "missing values" (individual entries with `NA` values for certain table columns).** Even when data coverage is generally high, individual entries may still have missing values. For time periods with high data coverage, we can sometimes make certain assumptions about missing values based on the clinical context, allowing us to perform single-value imputation (e.g., imputing all missing `mlaps` values with 0). 

<details>
<summary>***Expand this section to learn more about different types of missingness.***</summary>

In our scenario, missingness of `mlaps` represents an example of systematic missingness - also referred to as **"missing not at random" (MNAR)**. This means that the missingness is directly related to other predictor variables (e.g., patients' illness severity) and/or outcomes (e.g., in-hospital death). 

In other scenarios, values might be **missing at random (MAR)**. In that case, we should not perform single-value imputation. Instead, we may decide to use a complete-case analyses (i.e., only include encounters without missing values) or performing multiple imputation. See [here](https://onlinecjc.ca/article/S0828-282X(20)31111-9/fulltext#:~:text=Missing%20data%20is%20a%20common,all%20subjects%20in%20the%20sample) for a more detailed discussion on this.

</details>


### Outliers

In the summary plot above, we can see that there are some encounters with extremely long length of stay (LOS). Let's check what percentage of encounters have a length of stay longer than 90 days:

```{r}
100 * sum(cohort$los_days_derived > 90) / nrow(cohort)
```
Only ~0.5% of patients in our cohort stayed in hospital for more than 90 days. These patients are not representative of typical pneumonia patients, but instead, might have additional complications that we may not be able to appropriately account for in our simple model here. Specifically, our baseline covariates like `mlaps` are measured at the time of admission, but for patients with long LOS, several other events may occur throughout their hospitalization, which can affect clinical outcomes (in fact, patients with long LOS may have been admitted with a different condition, but then contracted pneumonia during their hospitalization, which was ultimately coded as their MRDx). 

To remove any bias these outliers might introduce in the model, we will exclude any encounters with long LOS. Here, we choose LOS <= 90 days as a cut-off, but in general, you should discuss the appropriate criterion with a clinical expert:

```{r}
data[, exclude_los := los_days_derived > 90]

cohort_table <- cohort_creation(
  cohort = list(data[incl1_gim == TRUE], # baseline cohort (discharges between 2018 - 2020)
                data[incl2_coverage == TRUE],
                data[incl2_coverage == TRUE & incl3_pneumonia == TRUE],
                data[incl2_coverage == TRUE & incl3_pneumonia == TRUE & excl1_transfer == FALSE],
                data[incl2_coverage == TRUE & incl3_pneumonia == TRUE & excl1_transfer == FALSE & excl2_ed == FALSE],
                data[incl2_coverage == TRUE & incl3_pneumonia == TRUE & excl1_transfer == FALSE & excl2_ed == FALSE & exclude_los == FALSE]),
  labels = c("All GEMINI encounters discharged between Apr 2018 - March 2020",
             "Encounters from hospitals with high data coverage",
             "Encounters with Pneumonia MRDx",
             "Encounters with an acute-care transfer",
             "Encounters not admitted from the ED",
             "Encounters with LOS > 90 days"
             ),
  exclusion_flag = c(FALSE, FALSE, FALSE, TRUE, TRUE, TRUE),
  big.mark = ","
)

cohort_table %>% knitr::kable(escape = FALSE, format = "html") %>%
  kable_styling("hover") %>%
  row_spec(7,  bold = TRUE)
```

Remember to update your `cohort` data table in line with the updated exclusion criteria: 

```{r}
cohort <- data[
  incl2_coverage == TRUE & 
    incl3_pneumonia == TRUE & 
    excl1_transfer == FALSE & 
    excl2_ed == FALSE & 
    exclude_los == FALSE # add new exclusion
]
```


**Note:** We generally do not recommend blindly removing outliers (e.g., based on generic criteria like +/-3 SDs) unless there is a conceptual rationale, or reasons to assume that outliers are implausible values that may reflect data quality issues (e.g., data entry errors). Instead, you should carefully consider what the potential reason for outliers is and whether they might affect the causal relationships between your variables of interest (e.g., see DAG above) in order to decide how to handle extreme values. 


### Variable transformation

During cohort generation, you will often need to create new derived variables, or perform additional preprocessing/transformations. For example, as shown in the plot above, `gender` is a categorical variable with 3 levels. Since `gender = "O"` is very rare and low cell counts represent a patient privacy issue, we will dichotomize this into a new variable "Female" vs. "Not female". We will also rename it into `sex_female` since CIHI data largely reflect biological sex, rather than gender: 

```{r}
cohort[, sex_female := gender == "F"]
```



## Final checks: Plot variables over time & by hospital

In the previous steps, we created the cohort and performed some data preprocessing. Let's plot our cohort variables over time (again) to check whether there are any weird time trends that may introduce biases. This is also a good way to double check whether any of our inclusion/exclusion steps may have introduced unexpected patterns in our data.

As an example, we'll just plot `mlaps` here again (but you should perform similar checks for all other relevant predictor/outcome variables). We would expect `mlaps` to remain fairly stable over time (with some noise). Since we already checked for lab data coverage, we would not expect there to be any time periods with missing entries:

```{r}
Rgemini::plot_over_time(cohort, plot_var = "mlaps", func = "mean")
```
  
**Note:** For the purpose of data exploration and data quality checks, it can often be helpful to plot means instead of medians. Because means are more sensitive to outliers than medians (see more details in the following section), it's often easier to detect unexpected trends/outliers when plotting the mean.


*  *  *  *

# Descriptive statistics

- Generate table1 and additional descriptive plots (but no outcome peeking)
- Double check that numbers match up across all variables
- Confirm that our cohort has sample size to support the analysis. 


*  *  *  *

# References & resources

- Missing data: https://onlinecjc.ca/article/S0828-282X(20)31111-9/fulltext#:~:text=Missing%20data%20is%20a%20common,all%20subjects%20in%20the%20sample
- Introduction to regression analyses: https://bookdown.org/rwnahhas/RMPH/



